{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lua-Nova/Modern-GAP-GNN/blob/main/ModernGAP_PMAT_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /home/amellow/.local/lib/python3.8/site-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /home/amellow/.local/lib/python3.8/site-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: torchaudio in /home/amellow/.local/lib/python3.8/site-packages (0.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /home/amellow/.local/lib/python3.8/site-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: numpy in /home/amellow/.local/lib/python3.8/site-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.22.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (7.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFQCNsDWU5mf",
        "outputId": "3eecdc41-7854-4790-f3e2-40793f899599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch-scatter 2.1.0+pt113cu116\n",
            "Uninstalling torch-scatter-2.1.0+pt113cu116:\n",
            "  Successfully uninstalled torch-scatter-2.1.0+pt113cu116\n",
            "Found existing installation: torch-sparse 0.6.15+pt113cu116\n",
            "Uninstalling torch-sparse-0.6.15+pt113cu116:\n",
            "  Successfully uninstalled torch-sparse-0.6.15+pt113cu116\n",
            "Found existing installation: torch-geometric 2.2.0\n",
            "Uninstalling torch-geometric-2.2.0:\n",
            "  Successfully uninstalled torch-geometric-2.2.0\n",
            "Found existing installation: torch-cluster 1.6.0+pt113cu116\n",
            "Uninstalling torch-cluster-1.6.0+pt113cu116:\n",
            "  Successfully uninstalled torch-cluster-1.6.0+pt113cu116\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Using cached https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0+pt113cu116\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Using cached https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.15%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.6 MB)\n",
            "Requirement already satisfied: scipy in /home/amellow/.local/lib/python3.8/site-packages (from torch-sparse) (1.9.3)\n",
            "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in /home/amellow/.local/lib/python3.8/site-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15+pt113cu116\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-cluster\n",
            "  Using cached https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
            "Requirement already satisfied: scipy in /home/amellow/.local/lib/python3.8/site-packages (from torch-cluster) (1.9.3)\n",
            "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in /home/amellow/.local/lib/python3.8/site-packages (from scipy->torch-cluster) (1.23.5)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0+pt113cu116\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-5bs9652u\n",
            "  Running command git clone -q https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-5bs9652u\n",
            "Requirement already satisfied: jinja2 in /home/amellow/.local/lib/python3.8/site-packages (from torch-geometric==2.2.0) (3.1.2)\n",
            "Requirement already satisfied: numpy in /home/amellow/.local/lib/python3.8/site-packages (from torch-geometric==2.2.0) (1.23.5)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /home/amellow/.local/lib/python3.8/site-packages (from torch-geometric==2.2.0) (5.9.4)\n",
            "Requirement already satisfied: pyparsing in /home/amellow/.local/lib/python3.8/site-packages (from torch-geometric==2.2.0) (3.0.9)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torch-geometric==2.2.0) (2.22.0)\n",
            "Requirement already satisfied: scikit-learn in /home/amellow/.local/lib/python3.8/site-packages (from torch-geometric==2.2.0) (1.1.3)\n",
            "Requirement already satisfied: scipy in /home/amellow/.local/lib/python3.8/site-packages (from torch-geometric==2.2.0) (1.9.3)\n",
            "Requirement already satisfied: tqdm in /home/amellow/.local/lib/python3.8/site-packages (from torch-geometric==2.2.0) (4.64.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/amellow/.local/lib/python3.8/site-packages (from jinja2->torch-geometric==2.2.0) (2.1.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /home/amellow/.local/lib/python3.8/site-packages (from scikit-learn->torch-geometric==2.2.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/amellow/.local/lib/python3.8/site-packages (from scikit-learn->torch-geometric==2.2.0) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773122 sha256=1a2117c7d54023babf4f70ee383187496a88633bbea5b8d404d90b61c0b1249c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rwfllzcl/wheels/ba/e1/8e/28297c3201c884d3ea8c47ba71a9e71e547e556c0caa9cf5a2\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.2.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Found existing installation: pyvacy 0.0.32\n",
            "Uninstalling pyvacy-0.0.32:\n",
            "  Successfully uninstalled pyvacy-0.0.32\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Processing /home/amellow/.cache/pip/wheels/0f/b9/fd/45fb9afde4d0efd0022f976cf3e53f058e01cf99812687e36f/pyvacy-0.0.32-py3-none-any.whl\n",
            "Installing collected packages: pyvacy\n",
            "Successfully installed pyvacy-0.0.32\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  #NVIDIA GPU version\n",
        "  %pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "  %pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "  %pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "  %pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "  %pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "else:\n",
        "  #CPU version\n",
        "  %pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric==2.0.0 -f https://data.pyg.org/whl/torch-1.12.0+cpu.html\n",
        "%pip uninstall pyvacy  --y\n",
        "%pip install pyvacy\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fBxqGGgYU6k-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch_geometric.nn import Sequential, GCNConv\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb1hVZklFoDP"
      },
      "source": [
        "## Encoder Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "1ScntAVtWL3M"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(11)\n",
        "# create classes for layers that are used a lot to avoid repeating code\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  # e.g. dimensions = [50,40,30,20]\n",
        "    def __init__(self, dimensions):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        layers = []\n",
        "        for i in range(len(dimensions)-1):\n",
        "          layers.append(nn.Linear(dimensions[i], dimensions[i+1]))\n",
        "          layers.append(nn.SELU(inplace=True))\n",
        "\n",
        "        self.linear_selu_stack = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_selu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF264FWv0pJI"
      },
      "source": [
        "## PMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "OMzLWqwF03Uu"
      },
      "outputs": [],
      "source": [
        "class AggregationModule(nn.Module):\n",
        "  edge_index = None\n",
        "\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "class PMA(AggregationModule):\n",
        "    # A - adjacency matrix     TODO: this should not be given to the module itself, it should access it in training (or from the graph dataset)\n",
        "    # num_hops - the number of hops covered by this GNN\n",
        "    def __init__(self, num_hops, sigma):\n",
        "        super().__init__()\n",
        "        self.num_hops = num_hops\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TEMP SOLUTION\n",
        "        if AggregationModule.edge_index is None:\n",
        "          raise RuntimeError(\"Set AggregationModule.edge_index [TEMP SOLUTION] before running\")\n",
        "        edge_index = AggregationModule.edge_index\n",
        "        A = get_adjacency_matrix(edge_index, x.size(dim=0))\n",
        "        out = [torch.nn.functional.normalize(x, dim=1)]\n",
        "        for k in range(self.num_hops):\n",
        "            aggr = torch.mm(torch.transpose(A, 0, 1), out[-1])\n",
        "            noised = aggr + torch.normal(torch.zeros(aggr.size()), std=self.sigma)\n",
        "            normalized = torch.nn.functional.normalize(noised, dim=1)\n",
        "            out.append(normalized)\n",
        "        return torch.stack(out)\n",
        "        # return torch.nn.functional.normalize(x, dim=1)\n",
        "\n",
        "class PMAT(AggregationModule):\n",
        "    # def __init__(self, num_hops, transform_dimensions):\n",
        "    def __init__(self, num_hops, encoding_dimensions, sigma):\n",
        "        super().__init__()\n",
        "        self.num_hops = num_hops\n",
        "        self.sigma = sigma\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        # self.transforms = nn.ModuleList()\n",
        "        self.attentions = nn.ModuleList()\n",
        "        for i in range(num_hops):\n",
        "          # self.transforms.append(nn.Linear(*transform_dimensions)) # Only 1 layer transformation\n",
        "          # self.attentions.append(MLP([2*transform_dimensions[-1], 1])) # Attention mechanism takes 2 encodings and outputs 1 weight\n",
        "          # TODO: Figure out if we want a transformer?\n",
        "          self.attentions.append(MLP([2*encoding_dimensions, 1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TEMP SOLUTION\n",
        "        if AggregationModule.edge_index is None:\n",
        "          raise RuntimeError(\"Set AggregationModule.edge_index [TEMP SOLUTION] before running\")\n",
        "        edge_index = AggregationModule.edge_index\n",
        "        out = [torch.nn.functional.normalize(x, dim=1)]\n",
        "        for k in range(self.num_hops):\n",
        "            # Do we need to do a transform? I reckon we can use raw encoding and aggregate according to attention (and then the Classification module)\n",
        "            # can handle how the aggregations get transformed\n",
        "            # h = self.transforms[k](out[-1])\n",
        "            h = out[-1]\n",
        "            e_values = self.attentions[k](h[edge_index.T].reshape(edge_index.size(dim=1), 2*h.size(dim=1))) # DPSGD to guarantee DP attention training\n",
        "            # we have to use Sigmoid because if we use Softmax, removing an edge will change the weight of all other edges in the neighbourhood\n",
        "            alpha_values = self.sigmoid(e_values)\n",
        "            alpha = torch.sparse_coo_tensor(edge_index,\n",
        "                                            alpha_values.reshape(edge_index.size(dim=1)),\n",
        "                                            (x.size(dim=0), x.size(dim=0)),\n",
        "                                            dtype=torch.float).transpose(0, 1)\n",
        "\n",
        "            aggr = torch.sparse.mm(alpha, h)\n",
        "            # Might need to not use \"transforms\" and instead do raw aggregations like the original PMA\n",
        "            # aggr = torch.mm(self.A, out[-1]) \n",
        "            # noised = aggr # TODO: add noise # Gaussian mechanism to guarantee DP for neighbourhood aggregation\n",
        "            noised = aggr + torch.normal(torch.zeros(aggr.size()), std=self.sigma).to(device)\n",
        "            normalized = torch.nn.functional.normalize(noised, dim=1)\n",
        "            out.append(normalized)\n",
        "        return torch.stack(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty_dao27oEAB"
      },
      "source": [
        "## Classification Module\n",
        "NOTE: \n",
        "\n",
        "MLP base: The first MLP in the cassification module. \n",
        "\n",
        "MLP head: The last MLP and takes the combined output of all MLP base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "7dLm3Q3HofT6"
      },
      "outputs": [],
      "source": [
        "class Classification(nn.Module):\n",
        "    # num_hops - the number of hops covered by this GNN\n",
        "    # encoder_dimensions - the MLP dimensions of each base MLP\n",
        "    # head_dimensions - the dimensions of the head MLP\n",
        "    def __init__(self, num_hops, encoder_dimensions, head_dimensions):\n",
        "        super().__init__()\n",
        "        self.base_mlps = nn.ModuleList()\n",
        "        self.num_hops = num_hops\n",
        "        if encoder_dimensions:\n",
        "          for i in range(num_hops+1):\n",
        "              self.base_mlps.append(MLP(encoder_dimensions))\n",
        "        self.head_mlp = MLP(head_dimensions) # TODO: should this be softmax? I think we add a softmax for classification tasks. We can test if it works better\n",
        "    \n",
        "    def forward(self, cache):\n",
        "        # forward through bases\n",
        "        out = []\n",
        "        for i in range(self.num_hops+1):\n",
        "          if self.base_mlps:\n",
        "            encoding = self.base_mlps[i](cache[i,:,:])\n",
        "            out.append(encoding) # add corresponding encoding\n",
        "          else:\n",
        "            out.append(cache[i, :, :])\n",
        "        # combine (use concatenation)\n",
        "        combined_x = torch.cat(out, dim=1)\n",
        "        # forward through head\n",
        "        return self.head_mlp(combined_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "evGOLmy-UrMs"
      },
      "outputs": [],
      "source": [
        "class GAP(nn.Module):\n",
        "  # encoder - pretrained encoder module\n",
        "  # pma - PMA module\n",
        "  # classification - classification module\n",
        "  def __init__(self, encoder, pma, classification): # TODO: decide whether we should recieve the models as parameters\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.encoder.requires_grad=False\n",
        "    self.pma = pma\n",
        "    self.classification = classification\n",
        "\n",
        "  def forward(self, x):\n",
        "    # initial node encoding\n",
        "    x_encoded = self.encoder(x)\n",
        "    # aggregation module\n",
        "    cache = self.pma(x_encoded) \n",
        "    # classification\n",
        "    return self.classification(cache) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WebCohAOIX0P"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Pf4P_bIZ5S",
        "outputId": "2734373b-5938-42cc-afe0-8be3e27ff98f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epsilon: 1.00, Delta: 0.50, Sigma: 1.51\n"
          ]
        }
      ],
      "source": [
        "node_level = True\n",
        "\n",
        "# Edge level DP\n",
        "agg_epsilon, agg_delta, epsilon_1, epsilon_5, pmat_epsilon, pmat_delta = 1, 0.5, 4, 4, 4, 0.5\n",
        "K_hop = 1\n",
        "agg_sigma = 1 / np.max(np.roots([K_hop/2, np.sqrt(2*K_hop*np.log(1/agg_delta)), -agg_epsilon]))\n",
        "# Node level DP\n",
        "if (node_level):\n",
        "  pass\n",
        "  # How do we calculate this?\n",
        "data = \"reddit\"\n",
        "batch_size = 1\n",
        "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128'\n",
        "print(f\"Epsilon: {agg_epsilon:>0.2f}, Delta: {agg_delta:>0.2f}, Sigma: {agg_sigma:>0.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDJP3FhOi_Ty"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "IPX-rb88ukrc"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "# this method partitions based on nodes (so edges between splits are not used)\n",
        "def train_test_split(dataset, test_ratio):\n",
        "    X, y, edge_index= dataset.x, dataset.y, dataset.edge_index\n",
        "    shuffle_ordering = torch.randperm(X.size(dim=0))\n",
        "\n",
        "    edge_mapping = torch.zeros(X.size(dim=0), dtype=torch.long)\n",
        "    edge_mapping[shuffle_ordering] = torch.arange(X.size(dim=0))\n",
        "\n",
        "    X = X[shuffle_ordering]\n",
        "    y = y[shuffle_ordering]\n",
        "    edge_index = edge_mapping[edge_index]\n",
        "\n",
        "    mask = torch.zeros(X.size(dim=0), dtype=torch.bool)\n",
        "    train_slice = int((1-test_ratio)*X.size(dim=0))\n",
        "    mask[:train_slice] = True\n",
        "\n",
        "    X_train = X[mask]\n",
        "    X_test = X[~mask]\n",
        "\n",
        "    y_train = y[mask]\n",
        "    y_test = y[~mask]\n",
        "\n",
        "    edge_index_train = edge_index[:, torch.logical_and(*mask[edge_index])]\n",
        "    edge_index_test = edge_index[:, torch.logical_and(*~mask[edge_index])] - train_slice\n",
        "\n",
        "    return Data(x=X_train, y=y_train, edge_index=edge_index_train), \\\n",
        "           Data(x=X_test, y=y_test, edge_index=edge_index_test)\n",
        "\n",
        "\n",
        "# returns filtered edge index, first removes edges that have removed src or dst nodes, then shifts indices of remained src/dst nodes\n",
        "def filter_edge_index(edge_index, filter):\n",
        "\n",
        "    node_indices = torch.arange(filter.size(dim=0))[filter]\n",
        "    edge_mapping = torch.zeros(filter.size(dim=0), dtype=torch.long)\n",
        "    edge_mapping[node_indices] = torch.arange(node_indices.size(dim=0))\n",
        "\n",
        "\n",
        "    edge_index = edge_index.to(torch.long)\n",
        "    edge_filter = torch.logical_and(*filter[edge_index])\n",
        "    return edge_mapping[edge_index[:, edge_filter]]\n",
        "\n",
        "def add_edge_to_low_degree_nodes(dataset, low_degree_threshold):\n",
        "    X, y, edge_index = dataset.x, dataset.y, dataset.edge_index\n",
        "\n",
        "    # get low degree nodes\n",
        "    A = get_adjacency_matrix(edge_index, X.size(dim=0))\n",
        "    sums = torch.sparse.sum(A, dim=1).to_dense()\n",
        "    mask = sums < low_degree_threshold\n",
        "    \n",
        "    # get edge_index mask for neighbours of low degree nodes\n",
        "    filter = mask[edge_index[0, :]]\n",
        "    low_degree_edges_index = edge_index[:, filter]\n",
        "    low_degree_A = get_adjacency_matrix(low_degree_edges_index, X.size(dim=0))\n",
        "\n",
        "    # get 1-hop neighbours and add to A \n",
        "    # NOTE: without sampling (just adds all 1-hop neighbours)\n",
        "    one_hop_low_degree_A = torch.sparse.mm(low_degree_A, A)\n",
        "    new_edge_index = torch.add(one_hop_low_degree_A, A).coalesce().indices()\n",
        "    return Data(x=X, y=y, edge_index=new_edge_index)\n",
        "    \n",
        "\n",
        "def prepare_dataset(dataset, threshold):\n",
        "    X, y, edge_index = dataset.x, dataset.y, dataset.edge_index\n",
        "\n",
        "    # remove labels with less examples than threshold\n",
        "    index_map = torch.zeros(y.size())\n",
        "    included_classes = y.unique(return_counts=True)[1] >= threshold\n",
        "    filter = included_classes[y]\n",
        "    # remap labels (i.e. if they were 0-8 and we remove 4 labels, new labels should be between 0 and 4)\n",
        "    label_mapping = torch.zeros(included_classes.size(dim=0), dtype=torch.long)\n",
        "    label_mapping[included_classes] = torch.arange(torch.count_nonzero(included_classes))\n",
        "\n",
        "    y = label_mapping[y[filter]].to(torch.long)\n",
        "    X = X[filter]\n",
        "\n",
        "    # remove edges that had their nodes removed\n",
        "    edge_index = filter_edge_index(edge_index, filter)\n",
        "\n",
        "    return Data(x=X, y=y, edge_index=edge_index)\n",
        "\n",
        "# make sparse adjacency matrix, A\n",
        "def get_adjacency_matrix(edge_index, num_nodes):\n",
        "    values = torch.ones(edge_index.size(dim=1), dtype = torch.int)\n",
        "    A = torch.sparse_coo_tensor(edge_index, values, (num_nodes, num_nodes), dtype=torch.float)\n",
        "    return A\n",
        "\n",
        "def standardization(train_dataset, test_dataset):\n",
        "    X = train_dataset.x\n",
        "    means = X.mean(dim=0, keepdim=True)\n",
        "    stds = X.std(dim=0, keepdim=True)\n",
        "    X_train = (X - means) / stds\n",
        "    X_test = (test_dataset.x - means) / stds\n",
        "    return Data(x=X_train, y=train_dataset.y, edge_index=train_dataset.edge_index), Data(x=X_test, y=test_dataset.y, edge_index=test_dataset.edge_index)\n",
        "\n",
        "def add_self_edges(dataset):\n",
        "    X = dataset.x\n",
        "    self_edges = torch.stack((torch.arange(X.size(dim=0)), torch.arange(X.size(dim=0))))\n",
        "    edge_index = torch.cat((dataset.edge_index, self_edges), dim=1)\n",
        "    return Data(x=X, y=dataset.y, edge_index=edge_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7oEXJ63oyl-"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aViLSsl2VD9K",
        "outputId": "86b999eb-e1e3-4e58-8867-aea34fab0178"
      },
      "outputs": [],
      "source": [
        "# Take a random sample Lt with sampling probability\n",
        "# L/Non('.', name='Computers')[0]\n",
        "# # prepare dataset by removing classes that have less than 1000 examples\n",
        "# dataset = prepare_dataset(dataset, 1000)\n",
        "# dataset = add_self_edges(dataset)\n",
        "# # get num classes\n",
        "# num_classes = torch.unique(dataset.y).size(dim=0)\n",
        "\n",
        "# # train/test split\n",
        "# train_dataset, test_dataset = train_test_split(dataset, 0.2)\n",
        "# print(train_dataset.edge_index.size(dim=1))\n",
        "# train_dataset = add_edge_to_low_degree_nodes(train_dataset, 10)\n",
        "# print(train_dataset.edge_index.size(dim=1))\n",
        "# test_dataset = add_edge_to_low_degree_nodes(test_dataset, 10)\n",
        "# train_dataset, test_dataset = standardization(train_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrAKSDBl03mk",
        "outputId": "aa68c479-c31a-4ec5-d7c9-55920e58b65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29610870\n",
            "29610870\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import Reddit\n",
        "dataset = Reddit('.')[0]\n",
        "# prepare dataset by removing classes that have less than 1000 examples\n",
        "dataset = prepare_dataset(dataset, 10000)\n",
        "dataset = add_self_edges(dataset)\n",
        "# get num classes\n",
        "num_classes = torch.unique(dataset.y).size(dim=0)\n",
        "\n",
        "# train/test split\n",
        "train_dataset, test_dataset = train_test_split(dataset, 0.2)\n",
        "print(train_dataset.edge_index.size(dim=1))\n",
        "# train_dataset = add_edge_to_low_degree_nodes(train_dataset, 10)\n",
        "print(train_dataset.edge_index.size(dim=1))\n",
        "# test_dataset = add_edge_to_low_degree_nodes(test_dataset, 10)\n",
        "train_dataset, test_dataset = standardization(train_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Swawd9we8f",
        "outputId": "e73fda43-91e5-4cf0-b744-c78122bf7e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([93592, 602])\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "X_train, y_train, edge_index_train = train_dataset.x, train_dataset.y, train_dataset.edge_index\n",
        "X_test, y_test, edge_index_test = test_dataset.x, test_dataset.y, test_dataset.edge_index\n",
        "\n",
        "# using large number like 10,000 so that all neighbours are sampled \n",
        "# I don't like how it samples, so I'm just gonna sample everything\n",
        "train_loader = NeighborLoader(train_dataset, num_neighbors=[X_train.size(dim=0)], batch_size=batch_size, shuffle=True)\n",
        "print(X_train.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot9FV6_9Ok3e"
      },
      "outputs": [],
      "source": [
        "# edge_index = torch.tensor([[0, 2, 0, 0, 2, 3, 1, 4, 1, 2, 4],\n",
        "#                            [1, 0, 3, 4, 1, 1, 4, 4, 1, 3, 3]], dtype=torch.long)\n",
        "# x = torch.tensor([[0, 1, 0], [1, 2, 2], [2, 3, 1], [3, 2, 4], [4, 2, 3]], dtype=torch.float)\n",
        "# y = torch.tensor([0, 1, 1, 2, 2], dtype=torch.long)\n",
        "# data = Data(x=x, y=y, edge_index=edge_index)\n",
        "# add_self_edges(data)\n",
        "# data = add_edge_to_low_degree_nodes(data, 3)\n",
        "# print(data.x)\n",
        "# data = standardization(data)\n",
        "# print(data.x)\n",
        "# print(data.x.std(dim=0))\n",
        "# print(data.edge_index)\n",
        "# print(get_adjacency_matrix(data.edge_index, x.size(dim=0)).to_dense())\n",
        "# train, test = train_test_split(data, 0.2)\n",
        "# print(train.x)\n",
        "# print(train.edge_index)\n",
        "# print(test.x)\n",
        "# print(test.edge_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Md2Ds3q3CY"
      },
      "source": [
        "## Train/Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "nu0AtfY7qzba"
      },
      "outputs": [],
      "source": [
        "\n",
        "# train\n",
        "def train(batch, model, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  AggregationModule.edge_index = batch.edge_index.to(device)\n",
        "  batch = batch.to(device)\n",
        "  # compute prediction error\n",
        "  pred = model(batch.x)\n",
        "  loss = loss_fn(pred, batch.y)\n",
        "  # backpropagation\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  # torch.cuda.empty_cache()\n",
        "\n",
        "# test\n",
        "def test(X, y, edge_index, split, model, loss_fn):\n",
        "    size = X.size(dim=0)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.inference_mode():\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        AggregationModule.edge_index = edge_index.to(device)\n",
        "        pred = model(X)\n",
        "        test_loss += loss_fn(pred, y).item()\n",
        "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    correct /= size\n",
        "    print(f\"{split.title()} Error: \\n Accuracy: {(100*correct):>0.1f}%, Loss: {test_loss:>8f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFvQEYa3j3O7"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XixvkAQpqcFM"
      },
      "source": [
        "Encoder Design\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "9ZT6RQbkiTbj"
      },
      "outputs": [],
      "source": [
        "# encoder\n",
        "dimensions = [602, 300, 60]\n",
        "encoder_model = nn.Sequential(\n",
        "    MLP(dimensions),\n",
        "    nn.Linear(dimensions[-1], num_classes),\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Jk2-tbqLer"
      },
      "source": [
        "Encoder Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HYGNjZgqo7k",
        "outputId": "1e997a6c-9bce-4312-c2f5-0ae175fd5646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Error: \n",
            " Accuracy: 53.6%, Loss: 1.729140\n",
            "Train Error: \n",
            " Accuracy: 62.7%, Loss: 1.644548\n",
            "Train Error: \n",
            " Accuracy: 69.0%, Loss: 1.589841\n",
            "Train Error: \n",
            " Accuracy: 71.4%, Loss: 1.566138\n",
            "Train Error: \n",
            " Accuracy: 74.2%, Loss: 1.538748\n",
            "Train Error: \n",
            " Accuracy: 74.7%, Loss: 1.530334\n",
            "Train Error: \n",
            " Accuracy: 75.4%, Loss: 1.522314\n",
            "Train Error: \n",
            " Accuracy: 76.4%, Loss: 1.513247\n",
            "Train Error: \n",
            " Accuracy: 73.8%, Loss: 1.537087\n",
            "Train Error: \n",
            " Accuracy: 77.0%, Loss: 1.505934\n",
            "Train Error: \n",
            " Accuracy: 74.9%, Loss: 1.526396\n",
            "Train Error: \n",
            " Accuracy: 77.2%, Loss: 1.503059\n",
            "Train Error: \n",
            " Accuracy: 77.5%, Loss: 1.499943\n",
            "Train Error: \n",
            " Accuracy: 77.1%, Loss: 1.503410\n",
            "Train Error: \n",
            " Accuracy: 77.1%, Loss: 1.503241\n",
            "Train Error: \n",
            " Accuracy: 75.9%, Loss: 1.515503\n",
            "Train Error: \n",
            " Accuracy: 77.2%, Loss: 1.501505\n",
            "Train Error: \n",
            " Accuracy: 79.1%, Loss: 1.482944\n",
            "Train Error: \n",
            " Accuracy: 74.6%, Loss: 1.526991\n",
            "Train Error: \n",
            " Accuracy: 77.5%, Loss: 1.498282\n",
            "Test Error: \n",
            " Accuracy: 76.7%, Loss: 1.506233\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "encoder_model = encoder_model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(encoder_model.parameters(), lr=1e-3)\n",
        "\n",
        "# if node_level:\n",
        "#   optimizer = op.optimizers.optimizer.DPOptimizer(\n",
        "#       # TODO: Fill out these parameters '?'\n",
        "#       optimizer=optimizer,\n",
        "#       noise_multiplier=?,\n",
        "#       max_grad_norm=?\n",
        "#   )\n",
        "\n",
        "for t in range(1000):\n",
        "    batch = next(iter(train_loader))\n",
        "    train(batch, encoder_model, loss_fn, optimizer)\n",
        "    if (t + 1) % 50 == 0:\n",
        "      test(X_train, y_train, edge_index_train, \"TRAIN\", encoder_model, loss_fn)\n",
        "test(X_test, y_test, edge_index_test, \"TEST\", encoder_model, loss_fn)\n",
        "print(\"Done!\")\n",
        "\n",
        "encoder = encoder_model[0]\n",
        "encoder.requires_grad=False\n",
        "\n",
        "# for name, param in encoder_model.named_parameters():\n",
        "#     if param.requires_grad:\n",
        "#         print(name, param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOoJSnrTSVWZ"
      },
      "source": [
        "## PMAT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "LKxUUyl_SW-i"
      },
      "outputs": [],
      "source": [
        "from pyvacy import optim, analysis\n",
        "# PMAT\n",
        "pmat_model = nn.Sequential(\n",
        "    encoder,\n",
        "    PMAT(K_hop, 60, agg_sigma),\n",
        "    Classification(K_hop, [], [(K_hop+1)*60, num_classes])\n",
        ")\n",
        "pmat_model = pmat_model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(encoder_model.parameters(), lr=1e-3)\n",
        "optimizer = optim.DPAdam(\n",
        "    l2_norm_clip=1.0,\n",
        "    noise_multiplier=1.8,\n",
        "    batch_size=batch_size,\n",
        "    params=pmat_model.parameters(),\n",
        "    lr=0.5e-1)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "CpsiubMeSoTE",
        "outputId": "3fab572f-342c-489c-c61b-51740ec68474"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 13.24 GiB (GPU 0; 15.72 GiB total capacity; 8.47 GiB already allocated; 161.44 MiB free; 14.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[189], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m epsilon \u001b[39m=\u001b[39m analysis\u001b[39m.\u001b[39mmoments_accountant(X_train\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), batch_size, \u001b[39m1.8\u001b[39m, t, pmat_delta)\n\u001b[1;32m      6\u001b[0m \u001b[39mif\u001b[39;00m (t \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m   test(X_train, y_train, edge_index_train, \u001b[39m\"\u001b[39;49m\u001b[39mTRAIN\u001b[39;49m\u001b[39m\"\u001b[39;49m, pmat_model, loss_fn)\n\u001b[1;32m      8\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOptimizer Achieves (\u001b[39m\u001b[39m{:>0.1f}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)-DP\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epsilon, pmat_delta))\n\u001b[1;32m      9\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLR:\u001b[39m\u001b[39m\"\u001b[39m, scheduler\u001b[39m.\u001b[39mget_last_lr()[\u001b[39m0\u001b[39m])\n",
            "Cell \u001b[0;32mIn[182], line 23\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(X, y, edge_index, split, model, loss_fn)\u001b[0m\n\u001b[1;32m     21\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m AggregationModule\u001b[39m.\u001b[39medge_index \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 23\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     24\u001b[0m test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(pred, y)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     25\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (pred\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m y)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[78], line 56\u001b[0m, in \u001b[0;36mPMAT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_hops):\n\u001b[1;32m     52\u001b[0m     \u001b[39m# Do we need to do a transform? I reckon we can use raw encoding and aggregate according to attention (and then the Classification module)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[39m# can handle how the aggregations get transformed\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[39m# h = self.transforms[k](out[-1])\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     h \u001b[39m=\u001b[39m out[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 56\u001b[0m     e_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattentions[k](h[edge_index\u001b[39m.\u001b[39;49mT]\u001b[39m.\u001b[39mreshape(edge_index\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m2\u001b[39m\u001b[39m*\u001b[39mh\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))) \u001b[39m# DPSGD to guarantee DP attention training\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39m# we have to use Sigmoid because if we use Softmax, removing an edge will change the weight of all other edges in the neighbourhood\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     alpha_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid(e_values)\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 13.24 GiB (GPU 0; 15.72 GiB total capacity; 8.47 GiB already allocated; 161.44 MiB free; 14.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "for t in range(100):\n",
        "    batch = next(iter(train_loader))\n",
        "    # print(batch.edge_index)\n",
        "    train(batch, pmat_model, loss_fn, optimizer)\n",
        "    epsilon = analysis.moments_accountant(X_train.size(dim=0), batch_size, 1.8, t, pmat_delta)\n",
        "    if (t + 1) % 10 == 0:\n",
        "      test(X_train, y_train, edge_index_train, \"TRAIN\", pmat_model, loss_fn)\n",
        "      print(\"Optimizer Achieves ({:>0.1f}, {})-DP\".format(epsilon, pmat_delta))\n",
        "      print(\"LR:\", scheduler.get_last_lr()[0])\n",
        "    scheduler.step()\n",
        "    if epsilon >= pmat_epsilon:\n",
        "      break\n",
        "# test(X_test, y_test, edge_index_test, \"TEST\", pmat_model, loss_fn)\n",
        "print(\"Done!\")\n",
        "\n",
        "pmat = pmat_model[1]\n",
        "pmat.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqf6_kLMUZUn"
      },
      "source": [
        "## Full Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2os_fvuNJmcJ"
      },
      "source": [
        "TODO:\n",
        "  - try other dataset\n",
        "  - compare with their implementation\n",
        "  - try train/test split across edges\n",
        "  - batch normalization\n",
        "  - add identity matrix to see performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo_SC_jUkl-y"
      },
      "source": [
        "Train full model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "UPx__jwgLUCL"
      },
      "outputs": [],
      "source": [
        "model = GAP(encoder, \n",
        "            PMA(K_hop, agg_sigma), \n",
        "            Classification(K_hop, [60, 20], [(K_hop+1)*20, num_classes]))\n",
        "# model = GAP(encoder, \n",
        "#             PMAT(K_hop, 60, agg_sigma), \n",
        "#             Classification(K_hop, [60, 20], [(K_hop+1)*20, num_classes]))\n",
        "model = model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z22WhxLcaveo",
        "outputId": "8a207048-a8e5-4cf9-f27f-8882c81fe072"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument values in method wrapper___sparse_coo_tensor_with_dims_and_tensors)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[168], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m      2\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n\u001b[0;32m----> 3\u001b[0m     train(batch, model, loss_fn, optimizer)\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m (t \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m       test(X_train, y_train, edge_index_train, \u001b[39m\"\u001b[39m\u001b[39mTRAIN\u001b[39m\u001b[39m\"\u001b[39m, model, loss_fn) \n",
            "Cell \u001b[0;32mIn[158], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(batch, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m \u001b[39m# compute prediction error\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m pred \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39;49mx)\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, batch\u001b[39m.\u001b[39my)\n\u001b[1;32m      9\u001b[0m \u001b[39m# backpropagation\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[80], line 16\u001b[0m, in \u001b[0;36mGAP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m x_encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m     15\u001b[0m \u001b[39m# aggregation module\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpma(x_encoded) \n\u001b[1;32m     17\u001b[0m \u001b[39m# classification\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification(cache)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[78], line 20\u001b[0m, in \u001b[0;36mPMA.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSet AggregationModule.edge_index [TEMP SOLUTION] before running\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m edge_index \u001b[39m=\u001b[39m AggregationModule\u001b[39m.\u001b[39medge_index\n\u001b[0;32m---> 20\u001b[0m A \u001b[39m=\u001b[39m get_adjacency_matrix(edge_index, x\u001b[39m.\u001b[39;49msize(dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\n\u001b[1;32m     21\u001b[0m out \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mnormalize(x, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_hops):\n",
            "Cell \u001b[0;32mIn[155], line 86\u001b[0m, in \u001b[0;36mget_adjacency_matrix\u001b[0;34m(edge_index, num_nodes)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_adjacency_matrix\u001b[39m(edge_index, num_nodes):\n\u001b[1;32m     85\u001b[0m     values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(edge_index\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mint)\n\u001b[0;32m---> 86\u001b[0m     A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msparse_coo_tensor(edge_index, values, (num_nodes, num_nodes), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat)\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m A\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument values in method wrapper___sparse_coo_tensor_with_dims_and_tensors)"
          ]
        }
      ],
      "source": [
        "for t in range(100):\n",
        "    batch = next(iter(train_loader))\n",
        "    train(batch, model, loss_fn, optimizer)\n",
        "    if (t + 1) % 10 == 0:\n",
        "      test(X_train, y_train, edge_index_train, \"TRAIN\", model, loss_fn) \n",
        "    scheduler.step()\n",
        "test(X_test, y_test, edge_index_test, \"TEST\", model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgX93DaHqqzh"
      },
      "source": [
        "## Backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vof5FsrKqroZ"
      },
      "outputs": [],
      "source": [
        "# # train\n",
        "# def train(dataloader, model, loss_fn, optimizer, print_every = 100):\n",
        "#     size = len(dataloader.dataset)\n",
        "#     model.train()\n",
        "#     for batch, (X, y) in enumerate(dataloader):\n",
        "#         X, y = X.to(device), y.to(device)\n",
        "\n",
        "#         # Compute prediction error\n",
        "#         pred = model(X)\n",
        "#         loss = loss_fn(pred, y)\n",
        "\n",
        "#         # Backpropagation\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         if batch % print_every == 0:\n",
        "#             loss, current = loss.item(), batch * len(X)\n",
        "#             print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# # test\n",
        "# def test(dataloader, model, loss_fn):\n",
        "#     size = len(dataloader.dataset)\n",
        "#     num_batches = len(dataloader)\n",
        "#     model.eval()\n",
        "#     test_loss, correct = 0, 0\n",
        "#     with torch.inference_mode():\n",
        "#         for X, y in dataloader:\n",
        "#             X, y = X.to(device), y.to(device)\n",
        "#             pred = model(X)\n",
        "#             test_loss += loss_fn(pred, y).item()\n",
        "#             correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "#     test_loss /= num_batches\n",
        "#     correct /= size\n",
        "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vb1hVZklFoDP",
        "GF264FWv0pJI",
        "Ty_dao27oEAB",
        "WebCohAOIX0P",
        "XDJP3FhOi_Ty",
        "E7oEXJ63oyl-",
        "a4Md2Ds3q3CY",
        "BgX93DaHqqzh"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
